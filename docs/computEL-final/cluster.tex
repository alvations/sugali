\section{Detecting Similar Languages} \label{sec:cluster}

To exemplify the use of SeedLing for computational research on low-resource languages, we experiment with automatic detection of similar languages. When working on endangered languages, documentary and computational linguists alike face the issue of lack of resources. It is often helpful to exploit lexical, syntactic or morphological knowledge about related or similar languages. For example, information about relatedness can be useful for identifying high-resource languages to be used in bootstrapping approaches such as those described in \newcite{yarowsky:ngai:2001} or \newcite{xia2007multilingual}.

Language classification can be carried out in various ways. Two common approaches are genealogical classification, mapping languages onto family trees according to their historical relatedness \cite{swadesh1952,starostin2010}; and typological classification, grouping languages according to linguistic features \cite{georgi2010wals,daume2009}. Both of these approaches require linguistic analysis. By contrast, we use surface features (character n-gram and word unigram frequencies) extracted from SeedLing, and apply an off-the-shelf hierarchical clustering algorithm.\footnote{\url{http://www.scipy.org/}} Specifically, each language is represented as a vector of frequencies of character bigrams, character trigrams, and word unigrams. Each of these three components is normalized to unit length.

\paragraph{Experimental Setup.}
We performed hierarchical clustering, which produces a tree structure: each leaf represents a language, and each node a cluster. We used linkage methods, which recursively build the tree starting from the leaves. Initially, each language is in a separate cluster, then we iteratively find the closest two clusters and merge them. Each time we do this, we take the two corresponding subtrees, and introduce a new node to join them.

We tested three methods, which differ in how they define the distance between two clusters. The \texttt{single} method considers all pairs of languages with one from each cluster, and finds the smallest distance. The \texttt{complete} method instead finds the largest distance. The \texttt{weighted} method calculates an average across all the pairwise differences, weighted according to the languages' positions in the tree.

While a tree structure might be linguistically useful, evaluating the structure is more awkward. However, the above methods can be easily used to produce partitional clusters, by stopping when we reach a certain number of clusters. We set the number of clusters to 147, the number of top-level genetic groupings in Ethnologue.

\begin{table}[t]
\begin{centering}

    \begin{tabular}{l|ccc}
    ~        & Precision & Recall       & F-score    \\ \hline
    \texttt{single} & 0.1958	& 0.6755	 & 0.1240  \\
	\texttt{complete} & \textbf{0.3153}	& 0.1699	 & \textbf{0.1420} \\
	\texttt{weighted} & 0.0614	& \textbf{0.8565}	 & 0.1099 \\ \hline
	\emph{random} & 0.1925 &	0.0927 & 	0.0692 \\
    \end{tabular}
\caption{Comparison of clustering algorithms}
\label{table:cluster}
\end{centering}
\end{table}

\paragraph{Evaluation.}
There are many possible metrics to evaluate the quality of a clustering compared to a gold standard. 
\newcite{amigo2009metrics} propose a set of criteria which a clustering evaluation metric should satisfy, and demonstrate that most popular metrics fail to satisfy at least one of these criteria.  However, they prove that they are satisfied by the BCubed metric, which we adopt for this reason.  To calculate this, we take the induced cluster and gold standard class for each language, and calculate the F-score of the cluster compared to the class.  These F-scores are then averaged across all languages.

In table \ref{table:cluster}, we give results of our clustering experiments, comparing the three clustering methods to a random baseline (clustering based on random distances, averaged over several runs).  The F-scores are comparable to those reported by \newcite{georgi2010wals}, even though we have only used surface features, while they used typological features taken from WALS.  This demonstrates that it possible for cross-linguistic research to be conducted even based on extremely shallow features.


%%% [ADD THIS!] As well as performing clustering, we can view this as an information retrieval task: given a language, what are similar languages?  To do this, we found the languages with the closest vectors of n-grams and words.  Since BCubed is calculated averaging across languages and not clusters, we can use exactly the same calculation, using the set of nearby languages in place of a cluster.


It is worth noting that precision is higher than recall.  This is perhaps to be expected, given that related languages using wildly differing orthographies will appear different.  Nonetheless, our system is reasonably capable of identifying languages which are both related and written similarly.


\paragraph{Qualitative Inspection.}
