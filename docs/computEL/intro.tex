\section{Introduction} \label{sec:intro}

At the time of writing, 7105 living languages are documented in Ethnologue,\footnote{\url{http://www.ethnologue.com}} but \newcite{krauss1992crisis} estimated 50\% of these are not being learnt by new generations of speakers, and risk extinction by the end of the century. However, only a fraction of the world's languages are well documented, fewer have machine-readable resources, and fewer again have resources with linguistic annotations \cite{maxwell2006annotation} - so the time to work on compiling these resources is now.

\textcolor{blue}{[move \& rewrite]}

Although there have been some previous attempts to produce cross-linguistic resources, there are few which both cover a wide range of languages, and are also machine-readable. We survey existing efforts in section \ref{sec:related}, and discuss their limitations in more detail.

Abney and Bird \shortcite{abney2010universal,abney2011data} posed the grand challenge of building a Universal Corpus, calling it the Human Language Project. Such a corpus would include all of the world's languages, in a consistent structure, facilitating large-scale cross-linguistic processing. They propose a specific data structure, which we describe and discuss in section \ref{sec:structure}. We have accepted their challenge, and have begun converting existing resources into a format consistent with their specifications for a universal corpus. We have drawn on four [or five?] web sources, cleaning and standardising them as described in section \ref{sec:sources}, to produce a seed corpus for the Human Language Project. In sections \ref{sec:stats} and \ref{sec:copyright}, we respectively give a summary of the data contained, and discuss copyright and distribution. \textcolor{blue}{[needs rewriting following reorganization.]}

[Note: remove this section if we don't do the work!] We believe the resulting corpus is the first of its kind: large enough and consistent enough to allow language processing on a grand scale. In section \ref{sec:cluster}, we give an example application of this corpus: language clustering. We use the frequencies of character n-grams and words to estimate the similarity of two languages. Despite this approach being highly dependent on orthography, we are able to reconstruct substantial parts of several language families, demonstrating the utility of this resource in cross-linguistic research. Finally, we discuss future work in section \ref{sec:future}, and conclude in section \ref{sec:conclusion}.

