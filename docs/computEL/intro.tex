\section{Introduction} \label{sec:intro}

At the time of writing, 7105 living languages are documented in Ethnologue,\footnote{\url{http://www.ethnologue.com}} but \newcite{krauss1992crisis} estimated 50\% of these are not being learnt by new generations of speakers, and risk extinction by the end of the century. However, only a fraction of the world's languages are well documented, fewer have machine-readable resources, and fewer again have resources with linguistic annotations \cite{maxwell2006annotation} - so the time to work on compiling these resources is now.

Several years ago, Abney and Bird \shortcite{abney2010universal,abney2011data} posed the challenge of building a Universal Corpus (UC), calling it the Human Language Project. Such a corpus would include all of the world's languages, in a consistent structure, facilitating large-scale cross-linguistic processing. The challenge was issued to the computational linguistics (CL) community, from the perspective that the data management, language processing, and machine learning tools\footnote{\textcolor{blue}{am I missing anything?}} well-known in CL must be brought to bear on the problems of documentary linguistics (DL), if we are to make any serious progress toward building such a resource. The UC as envisioned would facilitate broadly cross-lingual natural language processing (NLP), in particular driving innovation in research addressing NLP for low-resource languages (LRLs), which in turn drives developments in automated analysis, supporting the work of DL and increasing the efficiency of the language documentation process. \textcolor{blue}{[cite our AL work? is this too strong? also, run-on sentence. also, perhaps mention this workshop, which has precisely these goals]}

We have accepted this challenge and have begun converting existing resources into a format consistent with Abney and Bird's specifications for a universal corpus. We aim for a collection of resources that includes data: (a) from as many languages as possible, and (b) in a format which is both in accordance with best practice archiving recommendations and readily accessible as training data for machine learning and for other computational methods. \textcolor{blue}{[kind of clunky]} Of course there are many relevant efforts toward producing cross-linguistic resources, which we survey in section \ref{sec:related}. To the best of our knowledge, though, no existing effort meets these two desiderata to the extent of our corpus, which we will refer to throughout as the Human Language Project Seed Corpus (HLPSC). \textcolor{blue}{[other naming ideas?]}

To produce the HLPSC, we have drawn on four web sources, described in section \ref{sec:sources}. To bring the four resources into a single common format and data structure (section \ref{sec:structure}), each required different degrees and types of cleaning and standardisation. We describe the steps required in detail in section \ref{sec:case_studies}, presenting each resource as a separate case study. By doing so we hope to make future resource conversion efforts more efficient, as they can be guided by the lessons we learned in assembling our seed corpus. To that end, many of the resources described in \ref{sec:related} are perhaps candidates for inclusion in the next stage of building a UC.

We believe the resulting corpus, which at present covers 1374 languages from 106 language families, is the first of its kind: large enough and consistent enough to allow broadly multilingual language processing. To test this belief, we use the HLPSC in a test application (\ref{sec:cluster}): the task of language clustering. We use surface-level features (frequencies of character n-grams and words) extracted from our data to estimate the similarity of two languages.  \textcolor{blue}{[START HERE WITH CLEARER DESCRIPTION OF CLUSTERING RESULTS]}
Despite this approach being highly dependent on orthography, we are able to reconstruct substantial parts of several language families, demonstrating the utility of this resource in cross-linguistic research. Finally, we discuss future work in section \ref{sec:future}, and conclude in section \ref{sec:conclusion}.



% Abney and Bird \shortcite{abney2010universal,abney2011data} posed the grand challenge of building a Universal Corpus, calling it the Human Language Project. Such a corpus would include all of the world's languages, in a consistent structure, facilitating large-scale cross-linguistic processing. They propose a specific data structure, which we describe and discuss in section \ref{sec:structure}. We have accepted their challenge, and have begun converting existing resources into a format consistent with their specifications for a universal corpus. We have drawn on four [or five?] web sources, cleaning and standardising them as described in section \ref{sec:sources}, to produce a seed corpus for the Human Language Project. In sections \ref{sec:stats} and \ref{sec:copyright}, we respectively give a summary of the data contained, and discuss copyright and distribution. \textcolor{blue}{[needs rewriting following reorganization.]}

% [Note: remove this section if we don't do the work!] We believe the resulting corpus is the first of its kind: large enough and consistent enough to allow language processing on a grand scale. In section \ref{sec:cluster}, we give an example application of this corpus: language clustering. We use the frequencies of character n-grams and words to estimate the similarity of two languages. 


