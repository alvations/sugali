\section{Topics related to data release, etc.}


\subsection{Web as Corpus}

\textcolor{blue}{[This might want to go into related work...]}

In recent years, there has been increasing interesting in crawling websites to produce corpora. For example, \newcite{baroni2004bootcat} introduced the BootCaT toolkit to bootstrap specialised corpora, and \newcite{sharoff2006search} built corpora in various languages by issuing queries for random combinations of frequent words to create a balanced corpus not unlike the British National Corpus. \newcite{ferraresi2008ukwac} produced ukWaC, a large-scale English corpus, and \cite{baroni2009wacky} applied a similar method to produce corpora in German, Italian, and French. To build better quality web corpora, \newcite{versley2012quality} introduced the notion of content-sensitive boilerplate detection for cleaning data.

However, despite the amount of text they include, such corpora are usually limited in the number of languages represented. Some projects have emerged which strive for language diversity, such as the Leipzig Corpora Collection (LCC) \cite{biemann2007leipzig}, and COrpora from the Web (COW) \cite{schaefer2012cow}. The LCC currently offers free download of corpora in 117 languages, and dictionaries in many others, bringing the total number of languages up to 230. COW includes corpora in [XX] languages. These collections are certainly commendable, but they currently still fall short of universality - 230 languages represents only 3.3% of the world's languages [check figure].

\newcite{scannell2007crubadan} describes the Crúbadán Project, an attempt to crawl the web for data in a much larger range of languages, including endangered ones. At the time of writing, the number of languages represented has grown to [XXX] However, due to copyright issues, not all of the data is freely available. Motivated by similar copyright concerns, \newcite{brunello2009free} stressed the notion of building free corpora from the web using documents released under Creative Commons licenses.

Unlike the above efforts, we have not performed seed-query web-searching or web-crawling to achieve a balanced resource. Instead, we have focused on a small number of sources which contain data in a wide variety of languages, as described in section \ref{sec:sources}. However, these sources represent a variety of data types which a linguist might encounter, ranging from single-language text with significant non-linguistic markup (Wikipedia) to structured data with detailed linguistic annotations (ODIN).


\subsection{Copyright Issues} \label{sec:copyright}

Corpora copyright remains a grey area and a hobglobin for corpora compilation and distribution (Kilgarriff, 2002)[@Li, please add this reference to the bibliography file]. Often, free access to language data online does not imply the right to download, retain, remix and redistribute. 

ODIN refers itself as a database of IGTs that are returned as a result of querying from the source documents. As such, only the links to the documents and the appropriate citations and not the copies of the source documents are maintained on the ODIN site. However, the ODIN developers have left the users with no specific license/copyrights restriction for readaptation or redistribution.

The Omniglot phrases are free to be used for non-commercial purposes as stated in the FAQ page\footnote{http://www.omniglot.com/faqs.htm} but the rights of the Tower of Babel snippets from different bible sources remains iffy. For example, Omniglot cited www.bibles.org as one of its sources for the Tower of Babel chapter but the bibles.org site stated in fine print that `\emph{Except expressly permitted herein, you may not modify, copy, distribute, decompile, disassemble, reverse engineer, create derivative works, or otherwise use or manipulate the Site or any of its content without our prior written consent}'\footnote{http://bibles.org/pages/legal\#copyright}. [Ga: actually, about copying information, Omniglot says: \emph{'If you would like to copy or re-use any of the language-related articles, please ask the authors for permission. Contact details of the authors can be found at the bottom of the articles in most cases, if they're not there, please contact me, and I'll try to find them for you.'} - I suspect Adger has been given permission for each translation, and I think we would have to ask every single author if we want to re-distribute the data.  For the tower of babel translations, this could end up a nightmare...]

Although users are free to use, copy, modify, merge, publish and distribute Unicode Data Files, [Ga: Do we have a reference for this? Particularly distribution] there is no explicit ownership of the UDHR textfiles from the Unicode website. However, the original source of the UDHR documents from the Office of the High Commissioner for Human Rights clearly states that `\emph{None of the materials provided on this web site may be used, reproduced or transmitted, in whole or in part, in any form or by any means, electronic or mechanical, including photocopying, recording or the use of any information storage and retrieval system, except as provided for in the Terms and Conditions of Use of United Nations Web Sites, without permission in writing from the publisher.}'\footnote{http://www.un.org/en/aboutun/copyright/}. [Ga: Actually, it's not quite so bad - if we look at the terms and conditions, it says: \emph{'The United Nations grants permission to Users to visit the Site and to download and copy the information, documents and materials (collectively, “Materials”) from the Site for the User’s personal, non-commercial use, without any right to resell or redistribute them or to compile or create derivative works therefrom, subject to the terms and conditions outlined below, and also subject to more specific restrictions that may apply to specific Material within this Site.'}\footnote{http://www.un.org/en/aboutun/terms/} Specifically for the UDHR, it says: \emph{'If UDHR translations or materials are reproduced, users should make reference to this website as a source by providing a link.'}\footnote{http://www.ohchr.org/EN/UDHR/Pages/Introduction.aspx}  So, it looks like we're okay to use the UDHR as we currently are, but if we want to redistribute it, we need to get their permission in writing.]

The Wikipedia texts are licensed under Creative Commons Attribution Share-like\footnote{http://creativecommons.org/licenses/by-sa/3.0/legalcode}, which allows redistribution and adaptation. Hence the clean Wikipedia texts we have compiled can be freely redistributed without infringing any copyrights.  We have made this resource publically available.\footnote{To maintain anonymity, we do not give details of how to access the data, but, if accepted for publication, instructions will be included in the print version of this paper.}

%%
%To avoid any copyrights infringement, ... After surveying the rights for so many days, there is no way to redistribute the corpus unless we jumble up the sentences, but if we do that, the "document" level will be lost and that will not be a "good" resource to do NLP for LRL since data is already sparse.
%%

